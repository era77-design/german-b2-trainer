import streamlit as st
import re
from collections import Counter
from PIL import Image
import pytesseract
import pdfplumber
from pdf2image import convert_from_bytes
import requests

# --- 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
st.set_page_config(page_title="–ù–µ–º–µ—Ü–∫–∏–π B2 Trainer", layout="wide")
st.title("üá©üá™ –ù–µ–º–µ—Ü–∫–∏–π B2: –°–ª–æ–≤–∞—Ä—å + –°–∏–Ω–æ–Ω–∏–º—ã")

STOP_WORDS = {
    "der", "die", "das", "und", "ist", "in", "zu", "den", "dem", "des", 
    "mit", "auf", "f√ºr", "von", "ein", "eine", "einen", "sich", "aus",
    "dass", "nicht", "war", "aber", "man", "bei", "wie", "wir", "oder",
    "kann", "sind", "werden", "wird", "auch", "noch", "nur", "vor", "nach",
    "√ºber", "wenn", "zum", "zur", "habe", "hat", "durch", "unter", "diese",
    "telc", "deutsch", "pr√ºfung", "test", "seite", "page", "express", "hueber",
    "aufgabe", "l√∂sung", "antwortbogen", "teil", "kapitel", "√ºbung"
}

# --- 2. –§—É–Ω–∫—Ü–∏–∏ ---

@st.cache_data
def get_german_synonyms(word):
    """–ò—â–µ—Ç —Å–∏–Ω–æ–Ω–∏–º—ã —á–µ—Ä–µ–∑ OpenThesaurus API"""
    url = f"https://www.openthesaurus.de/synonyme/search?q={word}&format=json"
    try:
        response = requests.get(url, timeout=3) # –¢–∞–π–º-–∞—É—Ç 3 —Å–µ–∫, —á—Ç–æ–±—ã –Ω–µ –≤–∏—Å–µ–ª–æ
        data = response.json()
        synonyms = []
        for synset in data.get('synsets', []):
            for term in synset.get('terms', []):
                term_word = term.get('term')
                if term_word.lower() != word.lower() and len(term_word.split()) < 3:
                    synonyms.append(term_word)
        unique_synonyms = list(dict.fromkeys(synonyms))
        return ", ".join(unique_synonyms[:4])
    except Exception:
        return ""

def extract_text_safe(file_bytes, file_type, pages_to_scan):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ. –ï—Å–ª–∏ OCR ‚Äî —á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü.
    """
    text = ""
    error_message = None

    # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –≤—ã—Ç–∞—â–∏—Ç—å —Ç–µ–∫—Å—Ç –±–µ–∑ OCR (—ç—Ç–æ –±—ã—Å—Ç—Ä–æ –∏ –Ω–µ –µ—Å—Ç –ø–∞–º—è—Ç—å)
    if file_type == "application/pdf":
        try:
            with pdfplumber.open(file_bytes) as pdf:
                # –ß–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ N —Å—Ç—Ä–∞–Ω–∏—Ü –∏–ª–∏ –≤—Å–µ, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —Ü–∏—Ñ—Ä–æ–≤–æ–π
                for i, page in enumerate(pdf.pages):
                    if i >= pages_to_scan: break 
                    extracted = page.extract_text()
                    if extracted: text += extracted + "\n"
        except Exception:
            pass 

    # 2. –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç (< 50 —Å–∏–º–≤–æ–ª–æ–≤), –∑–Ω–∞—á–∏—Ç —ç—Ç–æ –°–ö–ê–ù. –í–∫–ª—é—á–∞–µ–º OCR —Å –ª–∏–º–∏—Ç–æ–º.
    if len(text) < 50:
        if file_type == "application/pdf":
            st.warning(f"üìÑ –≠—Ç–æ —Å–∫–∞–Ω. –†–∞—Å–ø–æ–∑–Ω–∞—é –ø–µ—Ä–≤—ã–µ {pages_to_scan} —Å—Ç—Ä., —á—Ç–æ–±—ã —Å–±–µ—Ä–µ—á—å –ø–∞–º—è—Ç—å...")
            try:
                # –í–ê–ñ–ù–û: seek(0) –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫—É—Ä—Å–æ—Ä –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞
                file_bytes.seek(0)
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¢–û–õ–¨–ö–û –Ω—É–∂–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (first_page, last_page)
                # –≠—Ç–æ —Å–ø–∞—Å–µ—Ç —Å–µ—Ä–≤–µ—Ä –æ—Ç –ø–∞–¥–µ–Ω–∏—è!
                images = convert_from_bytes(
                    file_bytes.read(), 
                    first_page=1, 
                    last_page=pages_to_scan
                )
                
                progress_bar = st.progress(0)
                for i, image in enumerate(images):
                    text += pytesseract.image_to_string(image, lang='deu') + "\n"
                    progress_bar.progress((i + 1) / len(images))
                    
            except Exception as e:
                error_message = f"–û—à–∏–±–∫–∞ PDF: {str(e)}"
        else:
            # –û–±—ã—á–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞
            try:
                image = Image.open(file_bytes)
                text = pytesseract.image_to_string(image, lang='deu')
            except Exception as e:
                error_message = str(e)

    if error_message:
        return f"ERROR: {error_message}"
        
    return text

def clean_and_count(text, min_len):
    """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–ª–æ–≤"""
    text = re.sub(r'[^a-zA-Z√§√∂√º√Ñ√ñ√ú√ü\s]', '', text)
    words = text.split()
    filtered = []
    for word in words:
        w_lower = word.lower()
        if len(w_lower) >= min_len and w_lower not in STOP_WORDS and not w_lower.isdigit():
            if word[0].isupper():
                filtered.append(word)
            else:
                filtered.append(w_lower)
    return Counter(filtered).most_common()

# --- 3. –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---

with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    min_len = st.slider("–ú–∏–Ω. –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞", 3, 12, 5)
    max_words = st.slider("–°–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –±—Ä–∞—Ç—å –≤ —Å–ª–æ–≤–∞—Ä—å", 10, 50, 20)
    # –ù–û–í–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê: –õ–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü
    pages_limit = st.slider("–°–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü —Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å (OCR)", 1, 10, 3, help="–ï—Å–ª–∏ —Ñ–∞–π–ª –±–æ–ª—å—à–æ–π, —Å—Ç–∞–≤—å –º–µ–Ω—å—à–µ 5, –∏–Ω–∞—á–µ —Å–µ—Ä–≤–µ—Ä –∑–∞–≤–∏—Å–Ω–µ—Ç!")

st.write("### üöÄ –ó–∞–≥—Ä—É–∑–∏ —Ç–µ—Å—Ç (PDF/JPG)")
st.info("üí° –°–æ–≤–µ—Ç: –î–ª—è –±–æ–ª—å—à–∏—Ö –∫–Ω–∏–≥ (PDF > 5 –ú–ë) –≤—ã–±–∏—Ä–∞–π –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö —Å–ª–µ–≤–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ 3-5 —Å—Ç—Ä–∞–Ω–∏—Ü –∑–∞ —Ä–∞–∑.")

uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", type=['pdf', 'png', 'jpg', 'jpeg'])

if uploaded_file:
    text_content = ""
    
    with st.spinner('–û–±—Ä–∞–±–æ—Ç–∫–∞...'):
        if uploaded_file.type == "application/pdf":
            text_content = extract_text_safe(uploaded_file, "application/pdf", pages_limit)
        else:
            text_content = extract_text_safe(uploaded_file, uploaded_file.type, 1)

    if text_content.startswith("ERROR:"):
        st.error("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞.")
        st.warning("–§–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥–µ–Ω –∏–ª–∏ —Å–ª–∏—à–∫–æ–º —Ç—è–∂–µ–ª—ã–π.")
        st.code(text_content)
        st.markdown("**–†–µ—à–µ–Ω–∏–µ:** –ü–æ–ø—Ä–æ–±—É–π '—Ä–∞—Å–ø–µ—á–∞—Ç–∞—Ç—å' —ç—Ç–æ—Ç PDF –≤ –Ω–æ–≤—ã–π —Ñ–∞–π–ª —á–µ—Ä–µ–∑ '–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ PDF' –Ω–∞ –∫–æ–º–ø—å—é—Ç–µ—Ä–µ.")
            
    elif text_content and len(text_content) > 10:
        all_words_data = clean_and_count(text_content, min_len)
        top_words = all_words_data[:max_words]
        
        st.success(f"–ü—Ä–æ—á–∏—Ç–∞–Ω–æ. –ù–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤: {len(all_words_data)}. –ò—â—É —Å–∏–Ω–æ–Ω–∏–º—ã...")
        
        table_data = []
        synonym_bar = st.progress(0)
        
        for i, (word, count) in enumerate(top_words):
            syns = get_german_synonyms(word)
            table_data.append({
                "–°–ª–æ–≤–æ": word,
                "–°–∏–Ω–æ–Ω–∏–º—ã (–¥–ª—è B2)": syns if syns else "‚Äî",
                "–ß–∞—Å—Ç–æ—Ç–∞": count,
                "–í—ã—É—á–∏—Ç—å": False
            })
            synonym_bar.progress((i + 1) / len(top_words))
            
        st.markdown("### üìö –°–ª–æ–≤–∞—Ä—å")
        st.data_editor(
            table_data,
            column_config={
                "–í—ã—É—á–∏—Ç—å": st.column_config.CheckboxColumn("–í —Å–ª–æ–≤–∞—Ä—å", default=False),
                "–°–∏–Ω–æ–Ω–∏–º—ã (–¥–ª—è B2)": st.column_config.TextColumn("–°–∏–Ω–æ–Ω–∏–º—ã"),
                "–ß–∞—Å—Ç–æ—Ç–∞": st.column_config.NumberColumn("–ü–æ–≤—Ç–æ—Ä–æ–≤")
            },
            height=600,
            use_container_width=True,
            hide_index=True
        )
    else:
        st.warning("–¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –ï—Å–ª–∏ —ç—Ç–æ PDF, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π.")
