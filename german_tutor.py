import streamlit as st
import re
from collections import Counter
from PIL import Image
import pytesseract
import pdfplumber
from pdf2image import convert_from_bytes
import requests

# --- 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
st.set_page_config(page_title="–ù–µ–º–µ—Ü–∫–∏–π B2 Trainer", layout="wide")
st.title("üá©üá™ –ù–µ–º–µ—Ü–∫–∏–π B2: –°–ª–æ–≤–∞—Ä—å + –°–∏–Ω–æ–Ω–∏–º—ã")

STOP_WORDS = {
    "der", "die", "das", "und", "ist", "in", "zu", "den", "dem", "des", 
    "mit", "auf", "f√ºr", "von", "ein", "eine", "einen", "sich", "aus",
    "dass", "nicht", "war", "aber", "man", "bei", "wie", "wir", "oder",
    "kann", "sind", "werden", "wird", "auch", "noch", "nur", "vor", "nach",
    "√ºber", "wenn", "zum", "zur", "habe", "hat", "durch", "unter", "diese",
    "telc", "deutsch", "pr√ºfung", "test", "seite", "page", "express", "hueber",
    "aufgabe", "l√∂sung", "antwortbogen", "teil", "kapitel", "√ºbung"
}

# --- 2. –§—É–Ω–∫—Ü–∏–∏ ---

@st.cache_data
def get_german_synonyms(word):
    """–ò—â–µ—Ç —Å–∏–Ω–æ–Ω–∏–º—ã —á–µ—Ä–µ–∑ OpenThesaurus API"""
    url = f"https://www.openthesaurus.de/synonyme/search?q={word}&format=json"
    try:
        response = requests.get(url, timeout=5)
        data = response.json()
        synonyms = []
        for synset in data.get('synsets', []):
            for term in synset.get('terms', []):
                term_word = term.get('term')
                if term_word.lower() != word.lower() and len(term_word.split()) < 3:
                    synonyms.append(term_word)
        unique_synonyms = list(dict.fromkeys(synonyms))
        return ", ".join(unique_synonyms[:4])
    except Exception:
        return ""

def extract_text_with_fallback(file_bytes, file_type):
    """–ß–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∏—Ç—ã–µ PDF."""
    text = ""
    error_message = None

    # 1. –ë—ã—Å—Ç—Ä–æ–µ —á—Ç–µ–Ω–∏–µ PDF (—Ç–µ–∫—Å—Ç–æ–≤—ã–π —Å–ª–æ–π)
    if file_type == "application/pdf":
        try:
            with pdfplumber.open(file_bytes) as pdf:
                for page in pdf.pages:
                    extracted = page.extract_text()
                    if extracted: text += extracted + "\n"
        except Exception:
            pass # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ —Ç—É—Ç, –ø–æ–ø—Ä–æ–±—É–µ–º OCR

    # 2. –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –º–∞–ª–æ ‚Äî –≤–∫–ª—é—á–∞–µ–º OCR
    if len(text) < 50:
        if file_type == "application/pdf":
            st.info("üîé –≠—Ç–æ —Å–∫–∞–Ω –∏–ª–∏ —Å–ª–æ–∂–Ω—ã–π PDF. –í–∫–ª—é—á–∞—é OCR (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)...")
            try:
                # –í–ê–ñ–ù–û: –ß–∏—Ç–∞–µ–º –±–∞–π—Ç—ã –∑–∞–Ω–æ–≤–æ, —Ç–∞–∫ –∫–∞–∫ pdfplumber –º–æ–≥ —Å–¥–≤–∏–Ω—É—Ç—å –∫—É—Ä—Å–æ—Ä
                file_bytes.seek(0)
                images = convert_from_bytes(file_bytes.read())
                
                progress_bar = st.progress(0)
                for i, image in enumerate(images):
                    text += pytesseract.image_to_string(image, lang='deu') + "\n"
                    progress_bar.progress((i + 1) / len(images))
            except Exception as e:
                # –õ–æ–≤–∏–º –æ—à–∏–±–∫—É –±–∏—Ç–æ–≥–æ PDF
                error_message = f"CRITICAL_PDF_ERROR: {str(e)}"
        else:
            # –ö–∞—Ä—Ç–∏–Ω–∫–∞
            try:
                image = Image.open(file_bytes)
                text = pytesseract.image_to_string(image, lang='deu')
            except Exception as e:
                error_message = str(e)

    if error_message:
        return f"ERROR: {error_message}"
        
    return text

def clean_and_count(text, min_len):
    """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–ª–æ–≤"""
    text = re.sub(r'[^a-zA-Z√§√∂√º√Ñ√ñ√ú√ü\s]', '', text)
    words = text.split()
    filtered = []
    for word in words:
        w_lower = word.lower()
        if len(w_lower) >= min_len and w_lower not in STOP_WORDS and not w_lower.isdigit():
            if word[0].isupper():
                filtered.append(word)
            else:
                filtered.append(w_lower)
    return Counter(filtered).most_common()

# --- 3. –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---

with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    min_len = st.slider("–ú–∏–Ω. –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞", 3, 12, 5)
    max_words = st.slider("–°–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", 10, 50, 20)

st.write("### üöÄ –ó–∞–≥—Ä—É–∑–∏ —Ç–µ—Å—Ç (PDF/JPG)")
st.info("üí° –ï—Å–ª–∏ –≤—ã–ª–µ—Ç–∞–µ—Ç –æ—à–∏–±–∫–∞ 'Syntax Error' ‚Äî –æ—Ç–∫—Ä–æ–π PDF –≤ –±—Ä–∞—É–∑–µ—Ä–µ –∏ –Ω–∞–∂–º–∏ '–ü–µ—á–∞—Ç—å' -> '–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ PDF'. –≠—Ç–æ –∏—Å–ø—Ä–∞–≤–∏—Ç —Ñ–∞–π–ª.")

uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", type=['pdf', 'png', 'jpg', 'jpeg'])

if uploaded_file:
    text_content = ""
    
    with st.spinner('–û–±—Ä–∞–±–æ—Ç–∫–∞...'):
        if uploaded_file.type == "application/pdf":
            text_content = extract_text_with_fallback(uploaded_file, "application/pdf")
        else:
            text_content = extract_text_with_fallback(uploaded_file, uploaded_file.type)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É
    if text_content.startswith("ERROR:"):
        st.error("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞.")
        st.warning("–§–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥–µ–Ω (—Å–ª–æ–º–∞–Ω–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ XRef).")
        st.markdown("**–ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:**\n1. –û—Ç–∫—Ä–æ–π —ç—Ç–æ—Ç PDF –Ω–∞ –∫–æ–º–ø—å—é—Ç–µ—Ä–µ (–≤ Chrome –∏–ª–∏ Adobe).\n2. –ù–∞–∂–º–∏ **–ü–µ—á–∞—Ç—å** -> –í—ã–±–µ—Ä–∏ –ø—Ä–∏–Ω—Ç–µ—Ä **'–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ PDF'**.\n3. –ó–∞–≥—Ä—É–∑–∏ –Ω–æ–≤—ã–π —Ñ–∞–π–ª —Å—é–¥–∞.")
        with st.expander("–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏"):
            st.code(text_content)
            
    elif text_content and len(text_content) > 10:
        all_words_data = clean_and_count(text_content, min_len)
        top_words = all_words_data[:max_words]
        
        st.success(f"–ù–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤: {len(all_words_data)}. –ü–æ–¥–±–∏—Ä–∞—é —Å–∏–Ω–æ–Ω–∏–º—ã –∫ —Ç–æ–ø-{max_words}...")
        
        table_data = []
        synonym_bar = st.progress(0)
        
        for i, (word, count) in enumerate(top_words):
            syns = get_german_synonyms(word)
            table_data.append({
                "–°–ª–æ–≤–æ": word,
                "–°–∏–Ω–æ–Ω–∏–º—ã (–¥–ª—è B2)": syns if syns else "‚Äî",
                "–ß–∞—Å—Ç–æ—Ç–∞": count,
                "–í—ã—É—á–∏—Ç—å": False
            })
            synonym_bar.progress((i + 1) / len(top_words))
            
        st.markdown("### üìö –°–ª–æ–≤–∞—Ä—å –¥–ª—è —É—Ä–æ–∫–∞")
        st.data_editor(
            table_data,
            column_config={
                "–í—ã—É—á–∏—Ç—å": st.column_config.CheckboxColumn("–í —Å–ª–æ–≤–∞—Ä—å", default=False),
                "–°–∏–Ω–æ–Ω–∏–º—ã (–¥–ª—è B2)": st.column_config.TextColumn("–°–∏–Ω–æ–Ω–∏–º—ã"),
                "–ß–∞—Å—Ç–æ—Ç–∞": st.column_config.NumberColumn("–ü–æ–≤—Ç–æ—Ä–æ–≤")
            },
            height=600,
            use_container_width=True,
            hide_index=True
        )
    else:
        st.warning("–¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ —Ñ–∞–π–ª –ø—É—Å—Ç.")
